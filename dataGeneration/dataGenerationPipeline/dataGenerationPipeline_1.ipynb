{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **Data Generation Pipeline**\n",
    "\n",
    "This notebook executes the full data generation pipeline that builds a structured, speaker-linked dataset from raw plenary session documents of the German Bundestag. It downloads, parses, normalizes, and enriches metadata from various sources including XML, JSON, and official politician registries. The pipeline extracts both speeches and audience contributions, links them to politicians and parties, and outputs clean, well-structured Pickle and Excel datasets. These outputs form the foundation for all subsequent NLP and machine learning tasks in this project.\n",
    "The pipeline logic and structure are based on the [open-discourse project](https://github.com/open-discourse/open-discourse/tree/main), which we discovered during initial research for the project.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **Resulting File Structure:**\n",
    "\n",
    "```\n",
    "team-16/\n",
    "├── dataGeneration/\n",
    "│   ├── dataGeneratorPipeline.ipynb  # YOU ARE HERE!\n",
    "│   ├── paths.py\n",
    "│   ├── dataGenerator_Clean_Text.py\n",
    "│   ├── dataGenerator_Extract_Contributions.py\n",
    "│   ├── dataGenerator_Match_Names.py\n",
    "│   └── bundestagsapi/\n",
    "data/\n",
    "├── dataGeneration/\n",
    "│   ├── rawData/\n",
    "│   │   ├── electoralTerms/\n",
    "│   │   │   └── electoralTerms.csv\n",
    "│   │   ├── politiciansRawData/\n",
    "│   │   │   ├── MDB_STAMMDATEN.XML\n",
    "│   │   │   ├── MDB_STAMMDATEN.DTD\n",
    "│   │   │   └── mgs.pkl\n",
    "│   │   ├── rawData19json/\n",
    "│   │   │   ├── protokoll_<Nr.>.json\n",
    "│   │   │   └── …\n",
    "│   │   ├── rawData20json/\n",
    "│   │   │   ├── protokoll_<Nr.>.json\n",
    "│   │   │   └── …\n",
    "│   │   ├── rawData19pdf/\n",
    "│   │   ├── rawData20pdf/\n",
    "│   │   ├── rawData19xml/\n",
    "│   │   │   ├── 19001.xml\n",
    "│   │   │   └── …\n",
    "│   │   ├── rawData20xml/\n",
    "│   │   │   ├── 20001.xml\n",
    "│   │   │   └── …\n",
    "│   │   │\n",
    "│   │   dataStage02/\n",
    "│   │   ├── data19xmlSplit/\n",
    "│   │   │   ├── 19001/\n",
    "│   │   │   │   ├── appendix.xml\n",
    "│   │   │   │   ├── meta_data.xml\n",
    "│   │   │   │   ├── toc.xml\n",
    "│   │   │   │   └── session_content.xml\n",
    "│   │   │   ├── 19002/ …\n",
    "│   │   │   └── …\n",
    "│   │   ├── data20xmlSplit/\n",
    "│   │   │   ├── 20001/\n",
    "│   │   │   │   ├── appendix.xml\n",
    "│   │   │   │   ├── meta_data.xml\n",
    "│   │   │   │   ├── toc.xml\n",
    "│   │   │   │   └── session_content.xml\n",
    "│   │   │   ├── 20002/ …\n",
    "│   │   │   └── …\n",
    "│   │   ├── dataFactionsStage02/\n",
    "│   │   │   └── factions.pkl\n",
    "│   │   ├── dataPoliticiansStage02/\n",
    "│   │   │   └── mps.pkl\n",
    "│   │   │\n",
    "│   │   dataStage03/\n",
    "│   │   ├── dataFactionsStage03/\n",
    "│   │   │   └── factionsAbbreviations.pkl\n",
    "│   │   ├── dataPoliticiansStage03/\n",
    "│   │   │   ├── mpsFactions.pkl\n",
    "│   │   │   ├── politicians.csv\n",
    "│   │   │   └── speaker_faction_lookup.csv\n",
    "│   │   │\n",
    "│   │   dataStage04/\n",
    "│   │   ├── contributionsExtended/\n",
    "│   │   │   ├── electoral_term_19/\n",
    "│   │   │   │   ├── 19001.pkl\n",
    "│   │   │   │   └── …\n",
    "│   │   │   ├── electoral_term_20/\n",
    "│   │   │   │   ├── 20001.pkl\n",
    "│   │   │   │   └── …\n",
    "│   │   ├── contributionsSimplified/\n",
    "│   │   │   ├── contributions_simplified_19.pkl\n",
    "│   │   │   ├── contributions_simplified_20.pkl\n",
    "│   │   │   └── contributions_simplified_19_20.pkl\n",
    "│   │   ├── speechContent/\n",
    "│   │   │   ├── electoral_term_19/\n",
    "│   │   │   │   └── speech_content.pkl\n",
    "│   │   │   ├── electoral_term_20/\n",
    "│   │   │   │   └── speech_content.pkl\n",
    "│   │   │\n",
    "│   │   dataStage05/\n",
    "│   │   ├── contributionsExtendedStage05/\n",
    "│   │   │   ├── electoral_term_19/\n",
    "│   │   │   │   ├── 19001.pkl\n",
    "│   │   │   │   └── …\n",
    "│   │   │   ├── electoral_term_20/\n",
    "│   │   │   │   ├── 20001.pkl\n",
    "│   │   │   │   └── …\n",
    "│   │   │\n",
    "│   │   dataStage06/\n",
    "│   │   ├── contributionsExtendedStage06/\n",
    "│   │   │   ├── electoral_term_19/\n",
    "│   │   │   │   ├── 19001.pkl\n",
    "│   │   │   │   └── …\n",
    "│   │   │   ├── electoral_term_20/\n",
    "│   │   │   │   ├── 20001.pkl\n",
    "│   │   │   │   └── …\n",
    "│   │\n",
    "├── dataFinalStage/\n",
    "│   ├── contributionsExtendedFinalStage/\n",
    "│   │   ├── contributions_extended_19_20.pkl\n",
    "│   │   ├── contributions_extended_19.pkl\n",
    "│   │   └── contributions_extended_20.pkl\n",
    "│   ├── contributionsSimplifiedFinalStage/\n",
    "│   │   ├── contributions_simplified_19.pkl\n",
    "│   │   ├── contributions_simplified_20.pkl\n",
    "│   │   └── contributions_simplified_19_20.pkl\n",
    "│   ├── speechContentFinalStage/\n",
    "│   │   ├── speech_content_19_20.pkl\n",
    "│   │   ├── speech_content_19.pkl\n",
    "│   │   └── speech_content_20.pkl\n",
    "│   └── factionsAbbreviations.pkl\n",
    "├── dataExcel/\n",
    "│   ├── finalStage/\n",
    "│   │   ├── contributions_extended_19_20_finalStage.xlsx\n",
    "│   │   ├── contributions_extended_19_finalStage.xlsx\n",
    "│   │   ├── contributions_extended_20_finalStage.xlsx\n",
    "│   │   ├── contributions_simplified_19_20_finalStage.xlsx\n",
    "│   │   ├── contributions_simplified_19_finalStage.xlsx\n",
    "│   │   ├── contributions_simplified_20_finalStage.xlsx\n",
    "│   │   ├── speech_content_19_20_finalStage.xlsx\n",
    "│   │   ├── speech_content_19_finalStage.xlsx\n",
    "│   │   ├── speech_content_20_finalStage.xlsx\n",
    "│   │   └── factionsAbbreviations.xlsx\n",
    "│   ├── dataGeneration/\n",
    "│   │   ├── mgs_wiki_rawData.xlsx\n",
    "│   │   ├── mps_stage02.xlsx\n",
    "│   │   ├── mpsFactions_stage03.xlsx\n",
    "│   │   ├── politicians_stage03.xlsx\n",
    "│   │   ├── speech_content_19_stage04.xlsx\n",
    "│   │   ├── speech_content_20_stage04.xlsx\n",
    "│   │   └── factions_stage02.xlsx\n",
    "```\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# **0 Data Generation Pipeline Setup**\n",
    "\n",
    "## **0.1 Setup Environment for Project**"
   ],
   "id": "c7b741f3f67f6a49"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# create a python environment 'nlp_project_environment' that already has all necessary packages installed with miniconda:\n",
    "!conda env create -f ../nlp_project_env_setup.yml\n",
    "# alternatively, run \"conda env create -f nlp_project_env_setup_mac.yml\" in terminal"
   ],
   "id": "1e3d0f270f1fbaf0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# install all necessary packages on selectd python interpreter:\n",
    "!pip install -r ../requirements.txt"
   ],
   "id": "c1f5f8e8d1ba155f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **0.2 Imports for Pipeline**",
   "id": "fd212d9a9fead58d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T19:35:01.095093Z",
     "start_time": "2025-06-18T19:35:01.088191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as et\n",
    "import regex\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import time\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "# helper functions and constants\n",
    "from dataGeneration.extract_contributions import extract\n",
    "from dataGeneration.clean_text import clean_name_headers\n",
    "from dataGeneration.match_names import insert_politician_id_into_contributions_extended\n",
    "import paths as PATHS"
   ],
   "id": "25b28cb6cc0b407a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **0.3 Read Json Files from API into Python Process**\n",
    "\n",
    "**The following structure needs to exist in data base directory for the pipeline to work:**\n",
    "```\n",
    "Data/\n",
    "├── dataGeneration/\n",
    "│   ├── rawData/\n",
    "│   │   ├── rawData19json/\n",
    "│   │   │   ├── protokoll_<Nr.>.json\n",
    "│   │   │   └── …\n",
    "│   │   ├── rawData20json/\n",
    "│   │   │   ├── protokoll_<Nr.>.json\n",
    "│   │   │   └── …\n",
    "```\n",
    "It can be generated via [LoadProtocols.java](../bundestagsapi/src/main/java/LoadProtocols.java) in the bundestagsapi."
   ],
   "id": "c6672459ba835245"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T08:31:15.478817Z",
     "start_time": "2025-05-24T08:31:14.414262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read all JSON-Files from Data20 and Data19\n",
    "files20 = glob.glob(str(PATHS.RAW_JSON_20 / \"*.json\"))\n",
    "protokolle20 = []\n",
    "files19 = glob.glob(str(PATHS.RAW_JSON_19 / \"*.json\"))\n",
    "protokolle19 = []\n",
    "\n",
    "for file in files20:\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        protokolle20.append(data)\n",
    "for file in files19:\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        protokolle19.append(data)\n",
    "\n",
    "print(f\"{len(protokolle20)} Dateien der 20. WP geladen.\")\n",
    "first20 = protokolle20[0]\n",
    "print(first20.keys())\n",
    "\n",
    "print(f\"{len(protokolle19)} Dateien der 19. WP geladen.\")\n",
    "first19 = protokolle19[0]\n",
    "print(first19.keys())"
   ],
   "id": "97fbe503324558fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258 Dateien der 20. WP geladen.\n",
      "dict_keys(['id', 'dokumentart', 'typ', 'dokumentnummer', 'wahlperiode', 'herausgeber', 'datum', 'aktualisiert', 'titel', 'fundstelle', 'pdf_hash', 'vorgangsbezug', 'vorgangsbezug_anzahl', 'text'])\n",
      "291 Dateien der 19. WP geladen.\n",
      "dict_keys(['id', 'dokumentart', 'typ', 'dokumentnummer', 'wahlperiode', 'herausgeber', 'datum', 'aktualisiert', 'titel', 'fundstelle', 'pdf_hash', 'vorgangsbezug', 'vorgangsbezug_anzahl', 'text'])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **1 Download raw data**",
   "id": "c0d7b66530f43da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **1.1 Download Plenary Protocols (.pdf & .xml) for Electoral Terms 19 and 20**\n",
    "- Fetches the PDF and XML files of all plenary protocols for the 19th and 20th electoral periods.\n",
    "- The files are retrieved by reading the corresponding .json files (which were previously downloaded via the bundestagsapi) and following the pdf_url and xml_url links contained in each.\n",
    "- Downloaded files are stored separately by format and electoral period.\n",
    "- This module ensures that all raw protocol documents are available locally in structured form. These files serve as the primary source for downstream parsing and processing steps.\n",
    "\n",
    "### **Input:**\n",
    "```\n",
    "rawData/\n",
    "├── rawData19json/\n",
    "│   ├── protokoll_<Nr.>.json\n",
    "│   └── …\n",
    "├── rawData20json/\n",
    "│   ├── protokoll_<Nr.>.json\n",
    "│   └── …\n",
    "```\n",
    "\n",
    "### **Output:**\n",
    "```\n",
    "rawData/\n",
    "├── rawData19pdf/\n",
    "├── rawData20pdf/\n",
    "├── rawData19xml/\n",
    "│   ├── 19001.xml\n",
    "│   └── …\n",
    "├── rawData20xml/\n",
    "│   ├── 20001.xml\n",
    "│   └── …\n",
    "```"
   ],
   "id": "ca2955993a5a7ffc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T08:36:28.541206Z",
     "start_time": "2025-05-24T08:31:16.480238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def download_documents(json_dir, target_dir, url_key, label):\n",
    "    \"\"\"\n",
    "    Downloads documents (PDF or XML) referenced in JSON files and saves them to the target directory.\n",
    "\n",
    "    :param json_dir (Path): Path to the directory containing the .json files.\n",
    "    :param target_dir (Path): Path to the directory where the downloaded files should be stored.\n",
    "    :param url_key (str): The key in the JSON structure pointing to the desired URL (e.g., \"pdf_url\", \"xml_url\").\n",
    "    :param label (str): A label to show in tqdm progress bar.\n",
    "    \"\"\"\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    for file in tqdm(json_files, desc=f\"Downloading {label}\"):\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            file_url = data.get(\"fundstelle\", {}).get(url_key)\n",
    "            if file_url:\n",
    "                filename = os.path.basename(file_url).split(\"#\")[0]\n",
    "                file_path = os.path.join(target_dir, filename)\n",
    "                if not os.path.exists(file_path):\n",
    "                    r = requests.get(file_url)\n",
    "                    with open(file_path, \"wb\") as out:\n",
    "                        out.write(r.content)\n",
    "\n",
    "# Downloads using centralized PATHS\n",
    "download_documents(PATHS.RAW_JSON_19, PATHS.RAW_PDF_19, \"pdf_url\", \"PDFs for 19th term\")\n",
    "download_documents(PATHS.RAW_JSON_19, PATHS.RAW_XML_19, \"xml_url\", \"XMLs for 19th term\")\n",
    "download_documents(PATHS.RAW_JSON_20, PATHS.RAW_PDF_20, \"pdf_url\", \"PDFs for 20th term\")\n",
    "download_documents(PATHS.RAW_JSON_20, PATHS.RAW_XML_20, \"xml_url\", \"XMLs for 20th term\")"
   ],
   "id": "cbd7730a64c1136d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading PDFs for 19th term: 100%|██████████| 291/291 [01:18<00:00,  3.71it/s]\n",
      "Downloading XMLs for 19th term: 100%|██████████| 291/291 [01:11<00:00,  4.09it/s]\n",
      "Downloading PDFs for 20th term: 100%|██████████| 258/258 [01:26<00:00,  3.00it/s]\n",
      "Downloading XMLs for 20th term: 100%|██████████| 258/258 [01:16<00:00,  3.39it/s]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **1.2 Download Metadata of All Members of the Bundestag (MdB)**\n",
    "Downloads and extracts a ZIP archive containing structured information (as a XML file) for all members of the German Bundestag from the 1st to the 20th electoral period. The files are provided by the Bundestag via the following URL:\n",
    "    https://www.bundestag.de/resource/blob/472878/7d4d417dbb7f7bd44508b3dc5de08ae2/MdB-Stammdaten-data.zip\n",
    "\n",
    "### **Input:**\n",
    "```\n",
    "None.\n",
    "```\n",
    "\n",
    "### **Output:**\n",
    "```\n",
    "rawData/\n",
    "├── politiciansRawData/\n",
    "│   ├── MDB_STAMMDATEN.XML\n",
    "│   └── MDB_STAMMDATEN.DTD\n",
    "```"
   ],
   "id": "60eec617b097a89d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T08:36:29.085891Z",
     "start_time": "2025-05-24T08:36:28.599324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# output directory\n",
    "RAW_XML = PATHS.RAW_POLITICIANS\n",
    "RAW_XML.mkdir(parents=True, exist_ok=True)\n",
    "#Download MDB Stammdaten.\n",
    "mp_base_data_link = \"https://www.bundestag.de/resource/blob/472878/7d4d417dbb7f7bd44508b3dc5de08ae2/MdB-Stammdaten-data.zip\"  # noqa: E501\n",
    "\n",
    "print(\"Download & unzip 'MP_BASE_DATA'...\", end=\"\", flush=True)\n",
    "\n",
    "try:\n",
    "    r = requests.get(mp_base_data_link)\n",
    "    r.raise_for_status()\n",
    "    with zipfile.ZipFile(io.BytesIO(r.content)) as z:\n",
    "        z.extractall(RAW_XML)\n",
    "    print(\"Done.\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"\\n❌ Download failed:\", e)\n",
    "except zipfile.BadZipFile:\n",
    "    print(\"\\n❌ The downloaded file is not a valid ZIP archive.\")\n",
    "\n",
    "#r = requests.get(mp_base_data_link)\n",
    "#with zipfile.ZipFile(io.BytesIO(r.content)) as z:\n",
    "#    z.extractall(RAW_XML)\n",
    "#print(\"Done.\")"
   ],
   "id": "dfd6edd09e71b807",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download & unzip 'MP_BASE_DATA'...Done.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **1.3 Split Plenary Protocol XML Files into Structural Components**\n",
    "\n",
    "This script processes raw plenary protocol XML files and splits each file into 4 logically separated XML documents:\n",
    "- toc.xml: Table of contents (XML-tag: vorspann)\n",
    "- session_content.xml: Speech content (XML-tag: sitzungsverlauf)\n",
    "- appendix.xml: Appendices such as voting results or exhibits (XML-tag: anlagen)\n",
    "- meta_data.xml: Metadata on speakers (XML-tag: rednerliste)\n",
    "\n",
    "### **Input:**\n",
    "```\n",
    "rawData/\n",
    "├── rawData19xml/*.xml\n",
    "│   ├── 19001.xml\n",
    "│   └── …\n",
    "├── rawData20xml/*.xml\n",
    "│   ├── 20001.xml\n",
    "│   └── …\n",
    "```\n",
    "\n",
    "### **Ouput:**\n",
    "```\n",
    "dataStage02/\n",
    "├── data19xmlSplit/\n",
    "│   ├── 19001/\n",
    "│   │   ├── appendix.xml\n",
    "│   │   ├── meta_data.xml\n",
    "│   │   ├── toc.xml\n",
    "│   │   └── session_content.xml\n",
    "│   ├── 19002/ …\n",
    "│   └── …\n",
    "├── data20xmlSplit/\n",
    "│   ├── 20001/\n",
    "│   │   ├── appendix.xml\n",
    "│   │   ├── meta_data.xml\n",
    "│   │   ├── toc.xml\n",
    "│   │   └── session_content.xml\n",
    "│   ├── 20002/ …\n",
    "│   └── …\n",
    "```"
   ],
   "id": "62c83363a0d94dd6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T08:36:38.041329Z",
     "start_time": "2025-05-24T08:36:29.105935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Input directory for 19. and 20. electoral period\n",
    "input_dirs = {\n",
    "    19: PATHS.RAW_XML_19,\n",
    "    20: PATHS.RAW_XML_20,\n",
    "}\n",
    "\n",
    "# Output directory for 19. and 20. electoral period\n",
    "output_dirs = {\n",
    "    19: PATHS.XML_SPLIT_19,\n",
    "    20: PATHS.XML_SPLIT_20,\n",
    "}\n",
    "\n",
    "# Pass through every electoral period\n",
    "for term_number in [19, 20]:\n",
    "    input_dir = input_dirs[term_number]\n",
    "    output_dir = output_dirs[term_number]\n",
    "\n",
    "    for xml_file_path in tqdm(sorted(input_dir.glob(\"*.xml\")), desc=f\"Parsing term {term_number}...\"):\n",
    "        try:\n",
    "            # read data\n",
    "            tree = et.parse(xml_file_path)\n",
    "            root = tree.getroot()\n",
    "            toc = et.ElementTree(root.find(\"vorspann\"))\n",
    "            session_content = et.ElementTree(root.find(\"sitzungsverlauf\"))\n",
    "            appendix = et.ElementTree(root.find(\"anlagen\"))\n",
    "            meta_data = et.ElementTree(root.find(\"rednerliste\"))\n",
    "\n",
    "            # using document-numbers to make folder structure\n",
    "            doc_number = regex.search(r\"\\d+\", xml_file_path.stem).group()\n",
    "            save_path = output_dir / doc_number\n",
    "            save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "            # save to xmls\n",
    "            toc.write(save_path / \"toc.xml\", encoding=\"UTF-8\", xml_declaration=True)\n",
    "            session_content.write(\n",
    "                save_path / \"session_content.xml\",\n",
    "                encoding=\"UTF-8\",\n",
    "                xml_declaration=True,\n",
    "            )\n",
    "            appendix.write(\n",
    "                save_path / \"appendix.xml\",\n",
    "                encoding=\"UTF-8\",\n",
    "                xml_declaration=True,\n",
    "            )\n",
    "            meta_data.write(\n",
    "                save_path / \"meta_data.xml\",\n",
    "                encoding=\"UTF-8\",\n",
    "                xml_declaration=True,\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing {xml_file_path}: {e}\")"
   ],
   "id": "4e00c0d77b9fc507",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing term 19...: 100%|██████████| 239/239 [00:04<00:00, 51.04it/s]\n",
      "Parsing term 20...: 100%|██████████| 214/214 [00:04<00:00, 50.46it/s]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **1.4 Extract MP Metadata from MP-Base-Data**\n",
    "\n",
    "Extracts biographical and institutional metadata for all members of the Bundestag from MDB_STAMMDATEN.xml.\n",
    "\n",
    "- **Each MP may get multiple entries depending on:**\n",
    "    - Name changes over time\n",
    "    - Multiple institutional affiliations (e.g., Bundestag and government office)\n",
    "    - Participation across multiple electoral terms\n",
    "- **The extracted data includes:**\n",
    "    - Biographical information: name, gender, profession, birth/death details\n",
    "    - Metadata: academic titles, aristocratic prefixes\n",
    "    - Electoral data: constituency, institution type (e.g. “Regierungsmitglied”)\n",
    "\n",
    "\n",
    "### **Input:**\n",
    "```\n",
    "rawData/\n",
    "├── politiciansRawData/\n",
    "│   └── MDB_STAMMDATEN.XML\n",
    "```\n",
    "\n",
    "### **Ouput:**\n",
    "```\n",
    "dataStage02/\n",
    "├── dataPoliticiansStage02/\n",
    "│   └── mps.pkl\n",
    "dataExcel/\n",
    "└── mps_stage02.xlsx\n",
    "```\n",
    "\n",
    "\n",
    "**Columns (mps.pkl):**\n",
    "| Column name       | Description                                                   |\n",
    "|------------------|---------------------------------------------------------------|\n",
    "| `ui`              | Unique politician identifier                                  |\n",
    "| `electoral_term`  | Electoral term in which the entry applies                     |\n",
    "| `first_name`      | First name(s) of the MP                                        |\n",
    "| `last_name`       | Last name of the MP                                           |\n",
    "| `birth_place`     | Place of birth                                                |\n",
    "| `birth_country`   | Country of birth                                              |\n",
    "| `birth_date`      | Date of birth                                                 |\n",
    "| `death_date`      | Date of death (or -1 if not applicable)                       |\n",
    "| `gender`          | Gender                                                        |\n",
    "| `profession`      | Profession                                                    |\n",
    "| `constituency`    | Electoral district (constituency)                             |\n",
    "| `aristocracy`     | Aristocratic title (e.g., Freiherr)                           |\n",
    "| `academic_title`  | Academic title (e.g., Dr., Prof.)                             |\n",
    "| `institution_type`| Type of institution (e.g., Fraktion/Gruppe, Regierungsmitglied)|\n",
    "| `institution_name`| Full name of the institution affiliation                      |"
   ],
   "id": "5d2df15b846dd184"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T08:36:41.589191Z",
     "start_time": "2025-05-24T08:36:38.057538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Input path for raw XML data\n",
    "MP_BASE_DATA = PATHS.RAW_POLITICIANS / \"MDB_STAMMDATEN.xml\"\n",
    "\n",
    "# Output directory for Stage 02\n",
    "POLITICIANS_STAGE_01 = PATHS.STAGE02 / \"dataPoliticiansStage02\"\n",
    "POLITICIANS_STAGE_01.mkdir(parents=True, exist_ok=True)\n",
    "save_path = PATHS.POLITICIANS_STAGE02  # = mps.pkl\n",
    "\n",
    "print(\"Process mps...\", end=\"\", flush=True)\n",
    "\n",
    "# read data\n",
    "tree = et.parse(MP_BASE_DATA)\n",
    "root = tree.getroot()\n",
    "\n",
    "# placeholder for final dataframe\n",
    "mps = {\n",
    "    \"ui\": [],\n",
    "    \"electoral_term\": [],\n",
    "    \"first_name\": [],\n",
    "    \"last_name\": [],\n",
    "    \"birth_place\": [],\n",
    "    \"birth_country\": [],\n",
    "    \"birth_date\": [],\n",
    "    \"death_date\": [],\n",
    "    \"gender\": [],\n",
    "    \"profession\": [],\n",
    "    \"constituency\": [],\n",
    "    \"aristocracy\": [],\n",
    "    \"academic_title\": [],\n",
    "    \"institution_type\": [],\n",
    "    \"institution_name\": [],\n",
    "}\n",
    "\n",
    "last_names_to_revisit = []\n",
    "i = 0\n",
    "\n",
    "# Iterate over all MDBs (Mitglieder des Bundestages) in XML File.\n",
    "for mdb in tqdm(tree.iter(\"MDB\"), desc=\"Verarbeite MdBs\"):\n",
    "    ui = mdb.findtext(\"ID\")\n",
    "\n",
    "    # This entries exist only once for every politician.\n",
    "    if mdb.findtext(\"BIOGRAFISCHE_ANGABEN/GEBURTSDATUM\") == \"\":\n",
    "        raise ValueError(\"Politician has to be born at some point.\")\n",
    "    else:\n",
    "        birth_date = str(mdb.findtext(\"BIOGRAFISCHE_ANGABEN/GEBURTSDATUM\"))\n",
    "\n",
    "    birth_place = mdb.findtext(\"BIOGRAFISCHE_ANGABEN/GEBURTSORT\")\n",
    "    birth_country = mdb.findtext(\"BIOGRAFISCHE_ANGABEN/GEBURTSLAND\")\n",
    "    if birth_country == \"\":\n",
    "        birth_country = \"Deutschland\"\n",
    "\n",
    "    if mdb.findtext(\"BIOGRAFISCHE_ANGABEN/STERBEDATUM\") == \"\":\n",
    "        death_date = -1\n",
    "    else:\n",
    "        death_date = str(mdb.findtext(\"BIOGRAFISCHE_ANGABEN/STERBEDATUM\"))\n",
    "\n",
    "    gender = mdb.findtext(\"BIOGRAFISCHE_ANGABEN/GESCHLECHT\")\n",
    "    profession = mdb.findtext(\"BIOGRAFISCHE_ANGABEN/BERUF\")\n",
    "\n",
    "    # Iterate over all name entries for the poltiician_id, e.g. necessary if\n",
    "    # name has changed due to a marriage or losing/gaining of titles like \"Dr.\"\n",
    "    # Or if in another period the location information\n",
    "    # changed \"\" -> \"Bremerhaven\"\n",
    "    for name in mdb.findall(\"./NAMEN/NAME\"):\n",
    "        first_name = name.findtext(\"VORNAME\")\n",
    "        last_name = name.findtext(\"NACHNAME\")\n",
    "        constituency = name.findtext(\"ORTSZUSATZ\")\n",
    "        aristocracy = name.findtext(\"ADEL\")\n",
    "        academic_title = name.findtext(\"AKAD_TITEL\")\n",
    "\n",
    "        # Hardcode Schmidt (Weilburg). Note: This makes 4 entries for\n",
    "        # Frank Schmidt!!\n",
    "        if regex.search(r\"\\(Weilburg\\)\", last_name):\n",
    "            last_name = last_name.replace(\" (Weilburg)\", \"\")\n",
    "            constituency = \"(Weilburg)\"\n",
    "\n",
    "        # Iterate over parliament periods the politician was member\n",
    "        # of the Bundestag.\n",
    "        for electoral_term in mdb.findall(\"./WAHLPERIODEN/WAHLPERIODE\"):\n",
    "            electoral_term_number = electoral_term.findtext(\"WP\")\n",
    "\n",
    "            # Iterate over faction membership in each parliament period, e.g.\n",
    "            # multiple entries exist if faction was changed within period.\n",
    "            for institution in electoral_term.findall(\"./INSTITUTIONEN/INSTITUTION\"):\n",
    "                institution_name = institution.findtext(\"INS_LANG\")\n",
    "                institution_type = institution.findtext(\"INSART_LANG\")\n",
    "\n",
    "                mps[\"ui\"].append(ui)\n",
    "                mps[\"electoral_term\"].append(electoral_term_number)\n",
    "                mps[\"first_name\"].append(first_name)\n",
    "                mps[\"last_name\"].append(last_name)\n",
    "                mps[\"birth_place\"].append(birth_place)\n",
    "                mps[\"birth_country\"].append(birth_country)\n",
    "                mps[\"birth_date\"].append(birth_date)\n",
    "                mps[\"death_date\"].append(death_date)\n",
    "                mps[\"gender\"].append(gender)\n",
    "                mps[\"profession\"].append(profession)\n",
    "                mps[\"constituency\"].append(constituency)\n",
    "                mps[\"aristocracy\"].append(aristocracy)\n",
    "                mps[\"academic_title\"].append(academic_title)\n",
    "\n",
    "                mps[\"institution_type\"].append(institution_type)\n",
    "                mps[\"institution_name\"].append(institution_name)\n",
    "\n",
    "# Postprocessing\n",
    "mps = pd.DataFrame(mps)\n",
    "mps[\"constituency\"] = mps[\"constituency\"].str.replace(\"[)(]\", \"\", regex=True)\n",
    "mps = mps.astype(dtype={\"ui\": \"int64\", \"birth_date\": \"str\", \"death_date\": \"str\"})\n",
    "\n",
    "# Save as Pickle\n",
    "mps.to_pickle(save_path)\n",
    "print(\"Done.\")\n",
    "\n",
    "# Save as Excel\n",
    "PATHS.DATA_EXCEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "mps.to_excel(PATHS.EXCEL_MPS_STAGE02, index=False)"
   ],
   "id": "c8b61dc05f8fe735",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process mps..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verarbeite MdBs: 4609it [00:00, 39307.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **1.5 Generate Electoral Terms Reference Table**\n",
    "\n",
    "Creates a CSV reference table listing all electoral terms from 1949 (1st term) to the current term (20th) and assigns each term:\n",
    "- a unique ID (1-based),\n",
    "- a start and end date (in seconds since the Unix epoch).\n",
    "\n",
    "The table can later be used to match speech or politician timestamps to the correct legislative period.\n",
    "\n",
    "\n",
    "### **Input:**\n",
    "```\n",
    "None.\n",
    "```\n",
    "\n",
    "### **Ouput:**\n",
    "```\n",
    "rawData/\n",
    "├── electoralTerms/\n",
    "│   └── electoralTerms.csv\n",
    "```\n",
    "\n",
    "\n",
    "**Columns (electoralTerms.csv):**\n",
    "| Column name | Description                              |\n",
    "|-------------|------------------------------------------|\n",
    "| `start_date`| Start of the electoral term (in seconds) |\n",
    "| `end_date`  | End of the electoral term (in seconds)   |\n",
    "| `id`        | Unique ID for the electoral term         |"
   ],
   "id": "96f74519314ebeb7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T08:36:41.623685Z",
     "start_time": "2025-05-24T08:36:41.613515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Output directory from centralized PATHS\n",
    "ELECTORAL_TERMS_DIR = PATHS.RAW_ELECTORAL_TERMS.parent\n",
    "ELECTORAL_TERMS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "electoral_terms = [\n",
    "    { \"start_date\": \"1949-09-07\", \"end_date\": \"1953-10-05\" },\n",
    "    { \"start_date\": \"1953-10-06\", \"end_date\": \"1957-10-14\" },\n",
    "    { \"start_date\": \"1957-10-15\", \"end_date\": \"1961-10-16\" },\n",
    "    { \"start_date\": \"1961-10-17\", \"end_date\": \"1965-10-18\" },\n",
    "    { \"start_date\": \"1965-10-19\", \"end_date\": \"1969-10-19\" },\n",
    "    { \"start_date\": \"1969-10-20\", \"end_date\": \"1972-12-12\" },\n",
    "    { \"start_date\": \"1972-12-13\", \"end_date\": \"1976-12-13\" },\n",
    "    { \"start_date\": \"1976-12-14\", \"end_date\": \"1980-11-03\" },\n",
    "    { \"start_date\": \"1980-11-04\", \"end_date\": \"1983-03-28\" },\n",
    "    { \"start_date\": \"1983-03-29\", \"end_date\": \"1987-02-17\" },\n",
    "    { \"start_date\": \"1987-02-18\", \"end_date\": \"1990-12-19\" },\n",
    "    { \"start_date\": \"1990-12-20\", \"end_date\": \"1994-11-09\" },\n",
    "    { \"start_date\": \"1994-11-10\", \"end_date\": \"1998-10-25\" },\n",
    "    { \"start_date\": \"1998-10-26\", \"end_date\": \"2002-10-16\" },\n",
    "    { \"start_date\": \"2002-10-17\", \"end_date\": \"2005-10-17\" },\n",
    "    { \"start_date\": \"2005-10-18\", \"end_date\": \"2009-10-26\" },\n",
    "    { \"start_date\": \"2009-10-27\", \"end_date\": \"2013-10-21\" },\n",
    "    { \"start_date\": \"2013-10-22\", \"end_date\": \"2017-10-23\" },\n",
    "    { \"start_date\": \"2017-10-24\", \"end_date\": \"2021-10-26\" },\n",
    "    { \"start_date\": \"2021-10-27\", \"end_date\": \"2025-10-29\" },\n",
    "]\n",
    "\n",
    "def string_to_seconds(date_string, ref_date = datetime(year=1970, month=1, day=1)):\n",
    "    date = datetime.strptime(date_string, \"%Y-%m-%d\")\n",
    "    return (date - ref_date).total_seconds()\n",
    "\n",
    "# convert dates to total seconds and add 1-based id to each term\n",
    "electoral_terms = [\n",
    "    {key: string_to_seconds(date_string) for key, date_string in term.items()} | {\"id\": idx + 1}\n",
    "    for idx, term in enumerate(electoral_terms)\n",
    "]\n",
    "\n",
    "# Save to CSV\n",
    "pd.DataFrame(electoral_terms).to_csv(PATHS.RAW_ELECTORAL_TERMS, index=False)\n",
    "print(f\"Saved to {PATHS.RAW_ELECTORAL_TERMS} — Done.\")"
   ],
   "id": "97996ab7dd4bdcdf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " saved to rawData/electoralTerms/electoralTerms.csv Done.\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
