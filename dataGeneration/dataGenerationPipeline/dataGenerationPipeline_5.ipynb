{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as et\n",
    "import regex\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import time\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "# helper functions and constants\n",
    "from dataGeneration.extract_contributions import extract\n",
    "from dataGeneration.clean_text import clean_name_headers\n",
    "from dataGeneration.match_names import insert_politician_id_into_contributions_extended\n",
    "import paths as PATHS"
   ],
   "id": "fb4f361ad15487e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Contributions**",
   "id": "af97ac8ef00e0183"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **5.1 Extended contributions - Normalize Speaker Names and Assign Party Affiliation**\n",
    "\n",
    "Processes the contributions_extended files from stage 4 and prepares them for further use by:\n",
    "- **Name Cleaning and Splitting:**\n",
    "    - The name_raw field (raw PDF name extractions) is cleaned from unwanted characters.\n",
    "    - Academic titles and nobility prefixes (e.g., Dr., von, Freiherr) are removed.\n",
    "    - Names are then split into first_name and last_name.\n",
    "    - Here the external logic clean_name_headers is used. It can be found in [clean_text.py](../clean_text.py).\n",
    "- **Faction Matching:**\n",
    "    - Party names are normalized using regex patterns.\n",
    "    - The faction field is mapped to a canonical abbreviation.\n",
    "    - Corresponding faction_id values are assigned from a precompiled faction lookup table.\n",
    "- **Output Generation:**\n",
    "    - At this point the fields first_name, last_name, acad_title, faction, and faction_id are properly cleaned and normalized.\n",
    "\n",
    "\n",
    "### **Input:**\n",
    "```\n",
    "dataStage04/\n",
    "├── contributionsExtended/\n",
    "│   ├── electoral_term_19/\n",
    "│   │   ├── 19001.pkl\n",
    "│   │   └── …\n",
    "│   ├── electoral_term_20/\n",
    "│   │   ├── 20001.pkl\n",
    "│   │   └── …\n",
    "dataStage03/\n",
    "├── dataFactionsStage03/\n",
    "│   └── factionsAbbreviations.pkl\n",
    "```\n",
    "\n",
    "### **Ouput:**\n",
    "```\n",
    "dataStage05/\n",
    "├── contributionsExtendedStage05/\n",
    "│   ├── electoral_term_19/\n",
    "│   │   ├── 19001.pkl\n",
    "│   │   └── …\n",
    "│   ├── electoral_term_20/\n",
    "│   │   ├── 20001.pkl\n",
    "│   │   └── …\n",
    "```"
   ],
   "id": "b73c2002b1963faf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Disabling pandas warnings.\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# input directory\n",
    "CONTRIBUTIONS_EXTENDED_INPUT = PATHS.CONTRIB_EXT_19.parent\n",
    "CONTRIBUTIONS_EXTENDED_OUTPUT = PATHS.STAGE05 / \"contributionsExtendedStage05\"\n",
    "factions = pd.read_pickle(PATHS.FACTIONS_ABBR_STAGE03)\n",
    "\n",
    "# output directory\n",
    "CONTRIBUTIONS_EXTENDED_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "faction_patterns = {\n",
    "    \"Bündnis 90/Die Grünen\": r\"(?:BÜNDNIS\\s*(?:90)?/?(?:\\s*D[1I]E)?|Bündnis\\s*90/(?:\\s*D[1I]E)?)?\\s*[GC]R[UÜ].?\\s*[ÑN]EN?(?:/Bündnis 90)?\",  # noqa: E501\n",
    "    \"CDU/CSU\": r\"(?:Gast|-)?(?:\\s*C\\s*[DSMU]\\s*S?[DU]\\s*(?:\\s*[/,':!.-]?)*\\s*(?:\\s*C+\\s*[DSs]?\\s*[UÙ]?\\s*)?)(?:-?Hosp\\.|-Gast|1)?\",  # noqa: E501\n",
    "    \"BP\": r\"^\\[?BP\\]?\",\n",
    "    \"DA\": r\"^\\[?DA\\]?\",\n",
    "    \"DP\": r\"^\\[?DP\\]?\",\n",
    "    \"DIE LINKE.\": r\"DIE ?LINKE|LINKEN|\\[DIE ?LINKE.\\]\",\n",
    "    \"DPB\": r\"^\\[?DPB\\]?\",\n",
    "    \"DRP\": r\"\\[?DRP(\\-Hosp\\.)?\\]?|^\\[?SRP\\]?|^\\[?DBP\\]?\",\n",
    "    \"FDP\": r\"\\s*F\\.?\\s*[PDO][.']?[DP]\\.?\",\n",
    "    \"Fraktionslos\": r\"(?:fraktionslos|Parteilos)\",\n",
    "    \"FU\": r\"^\\[?FU\\]?\",\n",
    "    \"FVP\": r\"^\\[?FVP\\]?\",\n",
    "    \"Gast\": r\"\\[?Gast\\]?\",\n",
    "    \"GB/BHE\": r\"\\[?(?:GB[/-]\\s*)?BHE(?:-DG)?\\]?\",\n",
    "    \"KPD\": r\"^\\[?KPD\\]?\",\n",
    "    \"NR\": r\"^\\[?NR\\]?$\",\n",
    "    \"PDS\": r\"(?:Gruppe\\s*der\\s*)?PDS(?:/(?:LL|Linke Liste))?\",\n",
    "    \"SPD\": r\"\\s*'?S(?:PD|DP)(?:\\.|-Gast)?\",\n",
    "    \"SSW\": r\"^\\[?SSW\\]?\",\n",
    "    \"SRP\": r\"^\\[?SRP\\]?\",\n",
    "    \"WAV\": r\"^\\[?WAV\\]?\",\n",
    "    \"Z\": r\"^\\[?Z\\]?$\",\n",
    "    \"AfD\": r\"^\\[?AfD\\]?$\",\n",
    "    \"DBP\": r\"^\\[?DBP\\]?$\",\n",
    "}\n",
    "\n",
    "\n",
    "def get_faction_abbrev(faction, faction_patterns):\n",
    "    \"\"\"matches the given faction and returns an id\"\"\"\n",
    "\n",
    "    for faction_abbrev, faction_pattern in faction_patterns.items():\n",
    "        if regex.search(faction_pattern, faction):\n",
    "            return faction_abbrev\n",
    "    return None\n",
    "\n",
    "\n",
    "# iterate over all electoral_term_folders\n",
    "for folder_path in sorted(CONTRIBUTIONS_EXTENDED_INPUT.iterdir()):\n",
    "    if not folder_path.is_dir():\n",
    "        continue\n",
    "\n",
    "    save_path = CONTRIBUTIONS_EXTENDED_OUTPUT / folder_path.stem\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # iterate over every contributions_extended file\n",
    "    for contrib_file in tqdm(folder_path.glob(\"*.pkl\"), desc=f\"Bearbeite {folder_path.stem}\"):\n",
    "        # read the spoken content csv\n",
    "        contributions_extended = pd.read_pickle(contrib_file)\n",
    "\n",
    "        # Insert acad_title column and extract plain name and titles.\n",
    "        # ADD DOCUMENTATION HERE\n",
    "        contributions_extended.insert(3, \"faction_id\", -1)\n",
    "        contributions_extended.insert(5, \"last_name\", \"\")\n",
    "        contributions_extended.insert(6, \"first_name\", \"\")\n",
    "        contributions_extended.insert(7, \"acad_title\", \"\")\n",
    "\n",
    "        # Current workaround, because some speeches seem to not be matched\n",
    "        # correctly. If second stage works without mistakes, this should not be\n",
    "        # necessary anymoregex.\n",
    "        contributions_extended = contributions_extended.fillna(\"\")\n",
    "\n",
    "        # Clean all the names still remaining from PDF Header.\n",
    "        # KEEP IN MIND THIS ALSO DELETES NAMES IN VOTING LISTS!!!\n",
    "        # And I think not all names are cleaned because of their position, e.g.\n",
    "        # \"Max Mustermann, Bundeskanzler\"\n",
    "        # THIS PART IS IMPORTANT AND SHOULD WORK PROPERLY, AS REOCCURING NAMES\n",
    "        # CAN INTRODUCE A LARGE BIAS IN TEXT ANALYSIS\n",
    "        names = contributions_extended[\"name_raw\"].to_list()\n",
    "        contributions_extended[\"content\"] = contributions_extended[\"content\"].apply(\n",
    "            clean_name_headers,\n",
    "            args=(np.unique(names), True),\n",
    "        )\n",
    "\n",
    "        contributions_extended.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        # Delete all not alphabetical chars, keep \"-\" as it occurs often in\n",
    "        # names.\n",
    "        # Question: Is any other character deleted, which could be in a name?\n",
    "        # Answer: I don't think so.\n",
    "        contributions_extended[\"name_raw\"] = contributions_extended[\"name_raw\"].astype(str)\n",
    "        contributions_extended[\"name_raw\"] = contributions_extended[\"name_raw\"].str.replace(\n",
    "            r\"[^a-zA-ZÖÄÜäöüß\\-]\", \" \", regex=True\n",
    "        )\n",
    "\n",
    "        # Replace more than two whitespaces with one.\n",
    "        contributions_extended[\"name_raw\"] = contributions_extended[\"name_raw\"].str.replace(\n",
    "            r\"  +\", \" \", regex=True\n",
    "        )\n",
    "\n",
    "        # Graf has to be checked again, as this is also a last_name.\n",
    "        # Titles have to be added: Like e.c. or when mistakes occur like b.c.\n",
    "        # Deleted \"Graf\" for now.\n",
    "        titles = [\n",
    "            \"Dr\",\n",
    "            \"Frau\",\n",
    "            \"D\",\n",
    "            \"-Ing\",\n",
    "            \"von\",\n",
    "            \"und\",\n",
    "            \"zu\",\n",
    "            \"van\",\n",
    "            \"de\",\n",
    "            \"Baron\",\n",
    "            \"Freiherr\",\n",
    "            \"Prinz\",\n",
    "            \"h\",\n",
    "            \"c\",\n",
    "        ]\n",
    "\n",
    "        # Split the name_raw column into it's components at space character.\n",
    "        first_last_titles = contributions_extended[\"name_raw\"].apply(str.split)\n",
    "\n",
    "        # Extract acad_title, if it is in the titles list.\n",
    "        contributions_extended[\"acad_title\"] = [\n",
    "            [acad_title for acad_title in title_list if acad_title in titles]\n",
    "            for title_list in first_last_titles\n",
    "        ]\n",
    "\n",
    "        # Remove titles from the first_last_name list.\n",
    "        for politician_titles in first_last_titles:\n",
    "            for acad_title in politician_titles[:]:\n",
    "                if acad_title in titles:\n",
    "                    politician_titles.remove(acad_title)\n",
    "\n",
    "        # Get the first and last name based on the amount of elements.\n",
    "        for index, first_last in enumerate(first_last_titles):\n",
    "            if len(first_last) == 1:\n",
    "                contributions_extended[\"first_name\"].iloc[index] = []\n",
    "                contributions_extended[\"last_name\"].iloc[index] = first_last[0]\n",
    "            # elif len(first_last) == 2:\n",
    "            elif len(first_last) >= 2:\n",
    "                contributions_extended[\"first_name\"].iloc[index] = first_last[:-1]\n",
    "                contributions_extended[\"last_name\"].iloc[index] = first_last[-1]\n",
    "            else:\n",
    "                contributions_extended[\"first_name\"].iloc[index] = []\n",
    "                contributions_extended[\"last_name\"].iloc[index] = \"\"\n",
    "\n",
    "        # look for parties in the faction column and replace them with a\n",
    "        # standardized faction name\n",
    "        for index, faction in zip(\n",
    "            contributions_extended.index, contributions_extended[\"faction\"]\n",
    "        ):\n",
    "            if faction:\n",
    "                faction_abbrev = get_faction_abbrev(\n",
    "                    str(faction), faction_patterns=faction_patterns\n",
    "                )\n",
    "\n",
    "                if faction_abbrev:\n",
    "                    contributions_extended.at[index, \"faction\"] = faction_abbrev\n",
    "                    try:\n",
    "                        contributions_extended.at[index, \"faction_id\"] = int(\n",
    "                            factions.loc[factions[\"abbreviation\"] == faction_abbrev, \"id\"].iloc[0]\n",
    "                        )\n",
    "                    except IndexError:\n",
    "                        contributions_extended.at[index, \"faction_id\"] = -1\n",
    "\n",
    "        contributions_extended.drop(columns=[\"name_raw\"], inplace=True)\n",
    "        contributions_extended.to_pickle(save_path / contrib_file.name)\n",
    "\n",
    "print(f\"contributions extended saved to {save_path}\")"
   ],
   "id": "773bdac1f995a9e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **5.2 Assign Speaker Identity to extended Contributions**\n",
    "\n",
    "Assigns a unique politician ID (ui) to each contribution entry by matching cleaned name components and metadata to the politician registry:\n",
    "- Loads the cleaned contributions from dataStage05.\n",
    "- Loads the complete list of politicians (including government and parliament members) from stage 3.\n",
    "- Cleans and normalizes name columns in the politician database to facilitate accurate matching.\n",
    "- Filters politicians per electoral term for performance and accuracy.\n",
    "- For each file:\n",
    "    - Matches speaker identity via first_name and last_name against the politician list.\n",
    "    - Assigns the corresponding ui (unique ID) to the contribution.\n",
    "    - This matching logic is encapsulated in insert_politician_id_into_contributions_extended() which can be found in [exctract_contributions.py](../extract_contributions.py)\n",
    "\n",
    "\n",
    "\n",
    "### **Input:**\n",
    "```\n",
    "dataStage03/\n",
    "├── dataPoliticiansStage03/\n",
    "│   └── politicians.csv\n",
    "dataStage05/\n",
    "├── contributionsExtendedStage05/\n",
    "│   ├── electoral_term_19/\n",
    "│   │   ├── 19001.pkl\n",
    "│   │   └── …\n",
    "│   ├── electoral_term_20/\n",
    "│   │   ├── 20001.pkl\n",
    "│   │   └── …\n",
    "```\n",
    "\n",
    "### **Ouput:**\n",
    "```\n",
    "dataStage06/\n",
    "├── contributionsExtendedStage06/\n",
    "│   ├── electoral_term_19/\n",
    "│   │   ├── 19001.pkl\n",
    "│   │   └── …\n",
    "│   ├── electoral_term_20/\n",
    "│   │   ├── 20001.pkl\n",
    "│   │   └── …\n",
    "```"
   ],
   "id": "cc1b489a9543c5f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# input directory\n",
    "CONTRIBUTIONS_EXTENDED_INPUT = PATHS.STAGE05 / \"contributionsExtendedStage05\"\n",
    "DATA_FINAL = PATHS.SPEAKER_LOOKUP_STAGE03.parent  # dataStage03/dataPoliticiansStage03\n",
    "\n",
    "# output directory\n",
    "CONTRIBUTIONS_EXTENDED_OUTPUT = PATHS.STAGE06 / \"contributionsExtendedStage06\"\n",
    "CONTRIBUTIONS_EXTENDED_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# MDBS\n",
    "politicians = pd.read_csv(PATHS.SPEAKER_LOOKUP_STAGE03.with_suffix(\".csv\"))\n",
    "politicians = politicians.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"ui\",\n",
    "        \"electoral_term\",\n",
    "        \"faction_id\",\n",
    "        \"first_name\",\n",
    "        \"last_name\",\n",
    "        \"gender\",\n",
    "        \"constituency\",\n",
    "        \"institution_type\",\n",
    "    ],\n",
    "].copy()\n",
    "\n",
    "politicians = politicians.astype(dtype={\"ui\": \"int64\"})\n",
    "\n",
    "# Some cleaning to make matching easier.\n",
    "politicians[\"constituency\"] = politicians[\"constituency\"].fillna(\"\")\n",
    "\n",
    "politicians[\"first_name\"] = politicians[\"first_name\"].str.lower()\n",
    "politicians[\"last_name\"] = politicians[\"last_name\"].str.lower()\n",
    "politicians[\"constituency\"] = politicians[\"constituency\"].str.lower()\n",
    "\n",
    "politicians[\"first_name\"] = politicians[\"first_name\"].str.replace(\"ß\", \"ss\", regex=False)\n",
    "politicians[\"last_name\"] = politicians[\"last_name\"].str.replace(\"ß\", \"ss\", regex=False)\n",
    "\n",
    "politicians[\"first_name\"] = politicians[\"first_name\"].apply(str.split)\n",
    "\n",
    "# iterate over all electoral_term_folders __________________________________________________\n",
    "for folder_path in sorted(CONTRIBUTIONS_EXTENDED_INPUT.iterdir()):\n",
    "    if not folder_path.is_dir():\n",
    "        continue\n",
    "\n",
    "    term_number = regex.search(r\"(?<=electoral_term_)\\d{2}\", folder_path.stem)\n",
    "    if term_number is None:\n",
    "        continue\n",
    "    term_number = int(term_number.group(0))\n",
    "\n",
    "    save_path = CONTRIBUTIONS_EXTENDED_OUTPUT / folder_path.stem\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Only select politicians of the election period.\n",
    "    politicians_electoral_term = politicians.loc[politicians[\"electoral_term\"] == term_number]\n",
    "    gov_members_electoral_term = politicians_electoral_term.loc[\n",
    "        politicians_electoral_term[\"institution_type\"] == \"Regierungsmitglied\"\n",
    "    ]\n",
    "\n",
    "    working = []\n",
    "    # iterate over every contributions_extended file\n",
    "    for contrib_ext_file_path in tqdm(\n",
    "        sorted(folder_path.glob(\"*.pkl\")),\n",
    "        desc=f\"Match contributions (term {term_number:>2})...\",\n",
    "    ):\n",
    "        # read the contributions_extended pickle file\n",
    "        contributions_extended = pd.read_pickle(contrib_ext_file_path)\n",
    "\n",
    "        (\n",
    "            contributions_extended_matched,\n",
    "            problems,\n",
    "        ) = insert_politician_id_into_contributions_extended(\n",
    "            contributions_extended,\n",
    "            politicians_electoral_term,\n",
    "            gov_members_electoral_term,\n",
    "        )\n",
    "\n",
    "        contributions_extended.to_pickle(save_path / contrib_ext_file_path.name)\n",
    "\n",
    "print (f\"contributions extended saved to {save_path}\")"
   ],
   "id": "527f7d67dc35c2fb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
