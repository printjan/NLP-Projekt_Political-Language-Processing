{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as et\n",
    "import regex\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import time\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "# helper functions and constants\n",
    "from dataGeneration.extract_contributions import extract\n",
    "from dataGeneration.clean_text import clean_name_headers\n",
    "from dataGeneration.match_names import insert_politician_id_into_contributions_extended\n",
    "import paths as PATHS"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **4 Spoken Content**",
   "id": "9916617f5454a813"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **4.1 Extract structured Speeches and Contributions from XML (Term 19 and 20)**\n",
    "\n",
    "**1. Speech Extraction:** Each session_content.xml file is parsed to extract speeches (rede), including speaker metadata including politician_id (from MDB data or speaker_faction_lookup) and faction_id (determined from fraktion tag or fallback lookup)\n",
    "- Handling of moderative speeches: The Bundespräsident:in, Vizepräsident:innen and Schriftführer:innen moderate sessions in the Bundestag. Their speeches are labeled with \"Presidium of Parliament\" in position_short. They have mostly short and repetitive speech-contributions which can easily be removed later\n",
    "- Handling of speeches of ministers: In the Bundestag ministers officially speak as representatives of the current Bundesregierung and therefore their speeches do not have a \"fraktion\" tag. We work around that by using the politician-faction-lookup table to assign a faction_id to them\n",
    "\n",
    "**2. Contribution Extraction:** Embedded commentary tags (kommentar) in the speech content are parsed using a regex-based extraction function:\n",
    "- Contributions are isolated, tokenized, and classified.\n",
    "- They are replaced in the speech content with a placeholder.\n",
    "- Metadata for each contribution is stored separately.\n",
    "- Here an external extraction function extract(…) is used: it can be found in [extract_contributions.py](../extract_contributions.py).\n",
    "\n",
    "This parser-step is central to transforming raw XML session data into:\n",
    "- Clean structured speech datasets suitable for NLP tasks\n",
    "- Detailed speaker-level contributions with speaker and faction alignment\n",
    "\n",
    "Internal Highlights:\n",
    "- Position Handling: Robust mapping of fraktion and rolle tags to standard position categories.\n",
    "- Speaker Disambiguation: Matching via speaker_id or fuzzy name search using first_name and last_name.\n",
    "- Date Handling: Converts sitzung-datum to Unix time.\n",
    "- Failsafes: Manual correction for broken XML dates (e.g., session 19158).\n",
    "\n",
    "\n",
    "### **Input:**\n",
    "```\n",
    "dataStage02/\n",
    "├── data19xmlSplit/\n",
    "│   ├── 19001/\n",
    "│   │   ├── appendix.xml\n",
    "│   │   ├── meta_data.xml\n",
    "│   │   ├── toc.xml\n",
    "│   │   └── session_content.xml\n",
    "│   ├── 19002/ …\n",
    "│   └── …\n",
    "├── data20xmlSplit/\n",
    "│   ├── 20001/\n",
    "│   │   ├── appendix.xml\n",
    "│   │   ├── meta_data.xml\n",
    "│   │   ├── toc.xml\n",
    "│   │   └── session_content.xml\n",
    "│   ├── 20002/ …\n",
    "│   └── …\n",
    "dataStage03/\n",
    "├── dataPoliticiansStage03/\n",
    "│   ├── politicians.csv\n",
    "├── dataFactionsStage03/\n",
    "│   ├── factionsAbbreviations.pkl\n",
    "│   └── speaker_faction_lookup.csv\n",
    "```\n",
    "\n",
    "### **Ouput:**\n",
    "```\n",
    "dataStage04/\n",
    "├── contributionsExtended/\n",
    "│   ├── electoral_term_19/\n",
    "│   │   ├── 19001.pkl\n",
    "│   │   └── …\n",
    "│   ├── electoral_term_20/\n",
    "│   │   ├── 20001.pkl\n",
    "│   │   └── …\n",
    "├── contributionsSimplified/\n",
    "│   ├── contributions_simplified_19.pkl\n",
    "│   ├── contributions_simplified_20.pkl\n",
    "│   └── contributions_simplified_19_20.pkl\n",
    "├── speechContent/\n",
    "│   ├── electoral_term_19/\n",
    "│   │   └── speech_content.pkl\n",
    "│   ├── electoral_term_20/\n",
    "│   │   └── speech_content.pkl\n",
    "dataFinalStage/\n",
    "├── contributionsSimplified/\n",
    "│   ├── contributions_simplified_19.pkl\n",
    "│   ├── contributions_simplified_20.pkl\n",
    "│   └── contributions_simplified_19_20.pkl\n",
    "dataExcel/\n",
    "├── finalStage/\n",
    "│   ├── contributions_simplified_19.pkl\n",
    "│   ├── contributions_simplified_20.pkl\n",
    "│   └── contributions_simplified_19_20.pkl\n",
    "```\n",
    "\n",
    "\n",
    "**Columns (speech_content_--)**:\n",
    "| Column name      | Description                                                  |\n",
    "|------------------|--------------------------------------------------------------|\n",
    "| `id`             | Unique ID of the speech                                      |\n",
    "| `session`        | Session number (e.g. \"001\")                                  |\n",
    "| `first_name`     | First name(s) of the speaker                                 |\n",
    "| `last_name`      | Last name of the speaker                                     |\n",
    "| `faction_id`     | Integer ID of the faction                                    |\n",
    "| `position_short` | Role class (Chancellor, Guest, Member of Parliament, Minister, Not found, Presidium of Parliament, Secretary of State)              |\n",
    "| `position_long`  | Full title (e.g. \"Parliamentary Secretary of State\")         |\n",
    "| `politician_id`  | Foreign key to matched person (or -1 if unknown)             |\n",
    "| `speech_content` | Full plain text of the speech and text position of contributions e.g. ({1}) |\n",
    "| `date`           | Date of the session in Unix timestamp format (seconds since 1970) |\n",
    "\n",
    "**Columns (contributions_simplified_--)**:\n",
    "| Column name      | Description                                 |\n",
    "|------------------|---------------------------------------------|\n",
    "| `text_position`  | Character index in the speech text          |\n",
    "| `content`        | Extracted contribution (e.g. \"[Applause]\")  |\n",
    "| `speech_id`      | Foreign key to the speech this belongs to   |"
   ],
   "id": "1238b65ccc2d2400"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:37:41.981822Z",
     "start_time": "2025-10-24T15:37:41.978722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Input directories\n",
    "ELECTORAL_TERM_19_20_INPUT = {\n",
    "    19: PATHS.XML_SPLIT_19,\n",
    "    20: PATHS.XML_SPLIT_20,\n",
    "}\n",
    "\n",
    "FACTIONS = PATHS.FACTIONS_ABBR_STAGE03\n",
    "politicians = PATHS.MPS_FACTIONS_STAGE03\n",
    "LOOKUP = PATHS.SPEAKER_LOOKUP_STAGE03\n",
    "lookup = pd.read_csv(LOOKUP)\n",
    "\n",
    "# Output directories\n",
    "base_output = PATHS.STAGE04\n",
    "ELECTORAL_TERM_19_20_OUTPUT = PATHS.SPEECH_CONTENT_19.parent\n",
    "CONTRIBUTIONS_SIMPLIFIED = PATHS.CONTRIB_SIMPLIFIED\n",
    "CONTRIBUTIONS_EXTENDED = PATHS.CONTRIB_EXT_19.parent\n",
    "\n",
    "ELECTORAL_TERM_19_20_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "CONTRIBUTIONS_SIMPLIFIED.mkdir(parents=True, exist_ok=True)\n",
    "CONTRIBUTIONS_EXTENDED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "faction_patterns = {\n",
    "    \"Bündnis 90/Die Grünen\": r\"(?:BÜNDNIS\\s*(?:90)?/?(?:\\s*D[1I]E)?|Bündnis\\s*90/(?:\\s*D[1I]E)?)?\\s*[GC]R[UÜ].?\\s*[ÑN]EN?(?:/Bündnis 90)?\",  # noqa: E501\n",
    "    \"CDU/CSU\": r\"(?:Gast|-)?(?:\\s*C\\s*[DSMU]\\s*S?[DU]\\s*(?:\\s*[/,':!.-]?)*\\s*(?:\\s*C+\\s*[DSs]?\\s*[UÙ]?\\s*)?)(?:-?Hosp\\.|-Gast|1)?\",  # noqa: E501\n",
    "    \"BP\": r\"^BP\",\n",
    "    \"DA\": r\"^DA\",\n",
    "    \"DP\": r\"^DP\",\n",
    "    \"DIE LINKE.\": r\"DIE LINKE\",\n",
    "    \"DPB\": r\"^DPB\",\n",
    "    \"DRP\": r\"DRP(\\-Hosp\\.)?|^SRP|^DBP\",\n",
    "    \"FDP\": r\"\\s*F\\.?\\s*[PDO][.']?[DP]\\.?\",\n",
    "    \"Fraktionslos\": r\"(?:fraktionslos|Parteilos)\",\n",
    "    \"FU\": r\"^FU\",\n",
    "    \"FVP\": r\"^FVP\",\n",
    "    \"Gast\": r\"Gast\",\n",
    "    \"GB/BHE\": r\"(?:GB[/-]\\s*)?BHE(?:-DG)?\",\n",
    "    \"KPD\": r\"^KPD\",\n",
    "    \"NR\": r\"^NR$\",\n",
    "    \"PDS\": r\"(?:Gruppe\\s*der\\s*)?PDS(?:/(?:LL|Linke Liste))?\",\n",
    "    \"SPD\": r\"\\s*'?S(?:PD|DP)(?:\\.|-Gast)?\",\n",
    "    \"SSW\": r\"^SSW\",\n",
    "    \"SRP\": r\"^SRP\",\n",
    "    \"WAV\": r\"^WAV\",\n",
    "    \"Z\": r\"^Z$\",\n",
    "    \"AfD\": r\"^AfD$\",\n",
    "    \"DBP\": r\"^DBP$\",\n",
    "}\n",
    "\n",
    "\n",
    "def get_position_short_and_long(position_raw):\n",
    "    \"\"\"matches the given position_raw and returns the long and short version\"\"\"\n",
    "    if position_raw in faction_patterns.keys() or regex.match(\n",
    "        r\"^[Bb]erichterstatter(in)?(\\s|$|,|.)\", position_raw\n",
    "    ):\n",
    "        return (\n",
    "            \"Member of Parliament\",\n",
    "            None if position_raw in faction_patterns.keys() else position_raw,\n",
    "        )\n",
    "    elif (\n",
    "        regex.match(r\"^[Bb]undestagspräsident(in)?(\\s|$|,|.)\", position_raw)\n",
    "        or regex.match(r\"^[Aa]lterspräsident(in)?(\\s|$|,|.)\", position_raw)\n",
    "        or regex.match(r\"^[Vv]izebundestagspräsident(in)?(\\s|$|,|.)\", position_raw)\n",
    "        or regex.match(r\"^[Ss]chriftführer(in)?(\\s|$|,|.)\", position_raw)\n",
    "        or position_raw.lower()\n",
    "        in [\n",
    "            \"präsidentin\",\n",
    "            \"präsident\",\n",
    "            \"präsident des deutschen bundestages\",\n",
    "            \"präsidentin des deutschen bundestages\",\n",
    "            \"vizepräsidentin\",\n",
    "            \"vizepräsident\",\n",
    "        ]\n",
    "    ):\n",
    "        return \"Presidium of Parliament\", position_raw\n",
    "    elif (\n",
    "        regex.match(r\"^[Bb]undespräsident(in)?(\\s|$|,|.)\", position_raw)\n",
    "        or regex.match(r\"^[Mm]inisterpräsident(in)?(\\s|$|,|.)\", position_raw)\n",
    "        or regex.match(r\"^[Ss]taatsminister(in)?(\\s|$|,|.)\", position_raw)\n",
    "        or regex.match(r\"^[Ss]enator(in)?(\\s|$|,|.)\", position_raw)\n",
    "        or regex.match(r\"^[Pp]räsident(in)?(\\s|$|,|.)\", position_raw)\n",
    "        or regex.match(r\"^[Gg]ast\", position_raw)\n",
    "    ):\n",
    "        return \"Guest\", position_raw\n",
    "    elif regex.match(r\"^[Bb]undeskanzler(in)?(\\s|$|,|.)\", position_raw):\n",
    "        return \"Chancellor\", None\n",
    "    elif regex.match(r\"^(Bundes)?[Mm]inister(in)?(\\s|$|,|.)\", position_raw):\n",
    "        return \"Minister\", position_raw\n",
    "    elif regex.match(\n",
    "        r\"^([Pp]arl\\s*\\.\\s+)?[Ss]taatssekretär(in)?(\\s|$|,|.)\", position_raw\n",
    "    ):\n",
    "        return \"Secretary of State\", position_raw\n",
    "    else:\n",
    "        return \"Not found\", None\n",
    "\n",
    "\n",
    "def get_first_last(name):\n",
    "    first_last = name.split()\n",
    "    if len(first_last) == 1:\n",
    "        first_name = \"\"\n",
    "        last_name = first_last[0]\n",
    "    elif len(first_last) >= 2:\n",
    "        first_name = first_last[:-1]\n",
    "        last_name = first_last[-1]\n",
    "    else:\n",
    "        first_name = \"ERROR\"\n",
    "        last_name = \"ERROR\"\n",
    "    return \" \".join(first_name), last_name\n",
    "\n",
    "def find_with_default(node, key, default):\n",
    "    result = node.find(key)\n",
    "    return default if result is None else result.text\n",
    "\n",
    "def get_faction_abbrev(faction, faction_patterns):\n",
    "    \"\"\"matches the given faction and returns an id\"\"\"\n",
    "\n",
    "    for faction_abbrev, faction_pattern in faction_patterns.items():\n",
    "        if regex.search(faction_pattern, faction):\n",
    "            return faction_abbrev\n",
    "    return None\n",
    "\n",
    "\n",
    "speech_content_id = 1000000\n",
    "\n",
    "speech_content = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": [],\n",
    "        \"session\": [],\n",
    "        \"first_name\": [],\n",
    "        \"last_name\": [],\n",
    "        \"faction_id\": [],\n",
    "        \"position_short\": [],\n",
    "        \"position_long\": [],\n",
    "        \"politician_id\": [],\n",
    "        \"speech_content\": [],\n",
    "        \"date\": [],\n",
    "    }\n",
    ")\n",
    "\n",
    "factions = pd.read_pickle(FACTIONS)\n",
    "\n",
    "politicians = pd.read_csv(politicians)\n",
    "politicians[\"last_name\"] = politicians[\"last_name\"].str.lower()\n",
    "politicians[\"last_name\"] = politicians[\"last_name\"].str.replace(\"ß\", \"ss\", regex=False)\n",
    "politicians[\"first_name\"] = politicians[\"first_name\"].str.lower()\n",
    "politicians[\"first_name\"] = politicians[\"first_name\"].str.replace(\"ß\", \"ss\", regex=False)\n",
    "politicians[\"first_name\"] = politicians[\"first_name\"].apply(str.split)\n",
    "\n",
    "for term_number, folder_path in ELECTORAL_TERM_19_20_INPUT.items():\n",
    "    if not folder_path.is_dir():\n",
    "        continue\n",
    "\n",
    "    if term_number is None:\n",
    "        continue\n",
    "\n",
    "    contributions_extended_output = CONTRIBUTIONS_EXTENDED / f\"electoral_term_{term_number}\"\n",
    "    term_spoken_content = ELECTORAL_TERM_19_20_OUTPUT / f\"electoral_term_{term_number}\"\n",
    "    #contributions_simplified_output = CONTRIBUTIONS_SIMPLIFIED / f\"electoral_term_{term_number}\"\n",
    "\n",
    "    contributions_extended_output.mkdir(parents=True, exist_ok=True)\n",
    "    term_spoken_content.mkdir(parents=True, exist_ok=True)\n",
    "    #contributions_simplified_output.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    speech_records = []\n",
    "\n",
    "    contributions_simplified = []\n",
    "\n",
    "    politicians_electoral_term = politicians.loc[\n",
    "        politicians[\"electoral_term\"] == term_number\n",
    "    ]\n",
    "\n",
    "    for session_path in tqdm(sorted(folder_path.iterdir()), desc=f\"Wahlperiode {term_number}\"):\n",
    "        if not session_path.is_dir():\n",
    "            continue\n",
    "\n",
    "        contributions_extended = []\n",
    "\n",
    "        session_content = et.parse(session_path / \"session_content.xml\")\n",
    "        meta_data = et.parse(session_path / \"meta_data.xml\")\n",
    "\n",
    "        date = meta_data.getroot().get(\"sitzung-datum\")\n",
    "        # Wrong date in xml file. Fixing manually\n",
    "        if session_path.stem == \"19158\":\n",
    "            date = \"07.05.2020\"\n",
    "        date = (\n",
    "            datetime.strptime(date, \"%d.%m.%Y\") - datetime(1970, 1, 1)\n",
    "        ).total_seconds()\n",
    "\n",
    "        root = session_content.getroot()\n",
    "\n",
    "        tops = root.findall(\"tagesordnungspunkt\")\n",
    "\n",
    "        id_Counter = 0\n",
    "\n",
    "        for top in tops:\n",
    "            speeches = top.findall(\"rede\")\n",
    "            for speech in speeches:\n",
    "                speaker = speech[0].find(\"redner\")\n",
    "                if speaker is None:\n",
    "                    continue\n",
    "                try:\n",
    "                    speaker_id = int(speaker.get(\"id\"))\n",
    "                except (ValueError, AttributeError):\n",
    "                    speaker_id = -1\n",
    "                name = speaker.find(\"name\")\n",
    "                first_name = find_with_default(name, \"vorname\", \"\")\n",
    "                last_name = find_with_default(name, \"nachname\", \"\")\n",
    "\n",
    "\n",
    "\n",
    "                position_raw_element = name.find(\"fraktion\")\n",
    "                if position_raw_element is not None and position_raw_element.text:\n",
    "                    position_raw = position_raw_element.text\n",
    "                else:\n",
    "                    role_element = name.find(\"rolle\")\n",
    "                    if role_element is not None:\n",
    "                        position_raw = find_with_default(role_element, \"rolle_lang\", \"\")\n",
    "                    else:\n",
    "                        position_raw = \"\"\n",
    "\n",
    "                #position_raw = name.find(\"fraktion\")\n",
    "                #if position_raw is None:\n",
    "                #    position_raw = name.find(\"rolle\")\n",
    "                #    if position_raw is not None:\n",
    "                #        position_raw = find_with_default(position_raw, \"rolle_lang\", \"\")\n",
    "                #    else:\n",
    "                #        position_raw = \"\"\n",
    "                #else:\n",
    "                #    position_raw = \"\"\n",
    "\n",
    "                faction_abbrev = get_faction_abbrev(\n",
    "                    str(position_raw), faction_patterns=faction_patterns\n",
    "                )\n",
    "                position_short, position_long = get_position_short_and_long(\n",
    "                    faction_abbrev\n",
    "                    if faction_abbrev\n",
    "                    else regex.sub(\"\\n+\", \" \", position_raw)\n",
    "                )\n",
    "                faction_id = -1\n",
    "\n",
    "                if faction_abbrev:\n",
    "                    # .iloc[0] is important right now, as some faction entries\n",
    "                    # in factions df share same faction_id, so always the first\n",
    "                    # one is chosen right now.\n",
    "                    faction_id = int(\n",
    "                        factions.loc[factions[\"abbreviation\"] == faction_abbrev, \"id\"].iloc[0]\n",
    "                    )\n",
    "\n",
    "                if faction_id == -1:\n",
    "                    row = lookup[(lookup[\"speaker_id\"] == speaker_id) & (lookup[\"electoral_term\"] == term_number)]\n",
    "                    if not row.empty:\n",
    "                        faction_id = int(row[\"faction_id\"].iloc[0])\n",
    "                    else:\n",
    "                        faction_id = -1\n",
    "\n",
    "\n",
    "                # additional logic for Minister\n",
    "                #if position_short == \"Minister\" and speaker_id != -1 and faction_id == -1:\n",
    "                #    # Politiker-Daten passend zur Wahlperiode und speaker_id filtern\n",
    "                #    politician_rows = politicians[\n",
    "                #        (politicians[\"ui\"] == speaker_id) & (politicians[\"electoral_term\"] == term_number)\n",
    "                #    ]\n",
    "                #    politician_ids = politician_rows.reset_indesx(drop=True)\n",
    "\n",
    "                #    faction_id_candidate = -1\n",
    "\n",
    "                #    for fid in politician_rows[\"faction_id\"]:\n",
    "                #        if fid != -1:\n",
    "                #            faction_id_candidate = fid\n",
    "\n",
    "                #    if (faction_id_candidate == -1) and (first_name == \"Nancy\") and (last_name == \"Faeser\"):\n",
    "                #        faction_id_candidate = 25\n",
    "\n",
    "                #    faction_id = faction_id_candidate\n",
    "\n",
    "\n",
    "                speech_text = \"\"\n",
    "                text_position = 0\n",
    "                for content in speech[1:]:\n",
    "                    tag = content.tag\n",
    "                    if tag == \"name\":\n",
    "                        speech_records.append(\n",
    "                            {\n",
    "                                \"id\": speech_content_id,\n",
    "                                \"session\": session_path.stem,\n",
    "                                \"first_name\": first_name,\n",
    "                                \"last_name\": last_name,\n",
    "                                \"faction_id\": faction_id,\n",
    "                                \"position_short\": position_short,\n",
    "                                \"position_long\": position_long,\n",
    "                                \"politician_id\": speaker_id,\n",
    "                                \"speech_content\": speech_text,\n",
    "                                \"date\": date,\n",
    "                            }\n",
    "                        )\n",
    "                        speech_content_id += 1\n",
    "                        faction_id = -1\n",
    "                        speaker_id = -1\n",
    "                        name = regex.sub(\":\", \"\", content.text).split()\n",
    "                        first_name, last_name = get_first_last(\" \".join(name[1:]))\n",
    "                        position_short, position_long = get_position_short_and_long(\n",
    "                            name[0]\n",
    "                        )\n",
    "                        possible_matches = politicians_electoral_term.loc[\n",
    "                            politicians_electoral_term[\"last_name\"] == last_name.lower()\n",
    "                        ]\n",
    "                        length = len(np.unique(possible_matches[\"ui\"]))\n",
    "                        if length == 1:\n",
    "                            speaker_id = int(possible_matches[\"ui\"].iloc[0])\n",
    "                        elif length > 1:\n",
    "                            first_name_set = set(\n",
    "                                [x.lower() for x in first_name.split()]\n",
    "                            )\n",
    "                            possible_matches = possible_matches.loc[\n",
    "                                ~possible_matches[\"first_name\"].apply(\n",
    "                                    lambda x: set(x).isdisjoint(first_name_set)\n",
    "                                )\n",
    "                            ]\n",
    "                            length = len(np.unique(possible_matches[\"ui\"]))\n",
    "                            if length == 1:\n",
    "                                speaker_id = int(possible_matches[\"ui\"].iloc[0])\n",
    "                        speech_text = \"\"\n",
    "                        text_position = 0\n",
    "                    elif tag == \"p\" and content.get(\"klasse\") == \"redner\":\n",
    "                        speech_records.append(\n",
    "                            {\n",
    "                                \"id\": speech_content_id,\n",
    "                                \"session\": session_path.stem,\n",
    "                                \"first_name\": first_name,\n",
    "                                \"last_name\": last_name,\n",
    "                                \"faction_id\": faction_id,\n",
    "                                \"position_short\": position_short,\n",
    "                                \"position_long\": position_long,\n",
    "                                \"politician_id\": speaker_id,\n",
    "                                \"speech_content\": speech_text,\n",
    "                                \"date\": date,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "                        speech_content_id += 1\n",
    "                        speech_text = \"\"\n",
    "                        text_position = 0\n",
    "                        speaker = content.find(\"redner\")\n",
    "                        speaker_id = int(speaker.get(\"id\"))\n",
    "                        possible_matches = politicians_electoral_term.loc[\n",
    "                            politicians_electoral_term[\"ui\"] == speaker_id\n",
    "                        ]\n",
    "                        if len(possible_matches) == 0:\n",
    "                            speaker_id = -1\n",
    "                        name = speaker.find(\"name\")\n",
    "                        try:\n",
    "                            first_name = name.find(\"vorname\").text\n",
    "                            last_name = name.find(\"nachname\").text\n",
    "                        except AttributeError:\n",
    "                            try:\n",
    "                                first_name, last_name = get_first_last(speech[0].text)\n",
    "                            except AttributeError:\n",
    "                                first_name = \"ERROR\"\n",
    "                                last_name = \"ERROR\"\n",
    "                        try:\n",
    "                            position_raw = name.find(\"fraktion\").text\n",
    "                        except (ValueError, AttributeError):\n",
    "                            position_raw = name.find(\"rolle\").find(\"rolle_lang\").text\n",
    "                        faction_abbrev = get_faction_abbrev(\n",
    "                            str(position_raw), faction_patterns=faction_patterns\n",
    "                        )\n",
    "\n",
    "                        faction_id = -1\n",
    "                        position_short, position_long = get_position_short_and_long(\n",
    "                            faction_abbrev\n",
    "                            if faction_abbrev\n",
    "                            else regex.sub(\"\\n+\", \" \", position_raw)\n",
    "                        )\n",
    "                        if faction_abbrev:\n",
    "                            faction = faction_abbrev\n",
    "                            # .iloc[0] is important right now, as some faction entries\n",
    "                            # in factions df share same faction_id, so always the first\n",
    "                            # one is chosen right now.\n",
    "                            faction_id = int(\n",
    "                                factions.loc[factions[\"abbreviation\"] == faction_abbrev, \"id\"].iloc[0]\n",
    "                            )\n",
    "                    elif tag == \"p\":\n",
    "                        try:\n",
    "                            speech_text += \"\\n\\n\" + content.text\n",
    "                        except TypeError:\n",
    "                            pass\n",
    "                    elif tag == \"kommentar\":\n",
    "                        (\n",
    "                            contributions_extended_frame,\n",
    "                            speech_replaced,\n",
    "                            contributions_simplified_frame,\n",
    "                            text_position,\n",
    "                        ) = extract(\n",
    "                            content.text,\n",
    "                            int(session_path.stem),\n",
    "                            speech_content_id,\n",
    "                            text_position,\n",
    "                            False,\n",
    "                        )\n",
    "                        speech_text += \"\\n\\n\" + speech_replaced\n",
    "                        contributions_extended.append(contributions_extended_frame)\n",
    "                        contributions_simplified.append(contributions_simplified_frame)\n",
    "\n",
    "                speech_records.append(\n",
    "                    {\n",
    "                        \"id\": speech_content_id,\n",
    "                        \"session\": session_path.stem,\n",
    "                        \"first_name\": first_name,\n",
    "                        \"last_name\": last_name,\n",
    "                        \"faction_id\": faction_id,\n",
    "                        \"position_short\": position_short,\n",
    "                        \"position_long\": position_long,\n",
    "                        \"politician_id\": speaker_id,\n",
    "                        \"speech_content\": speech_text,\n",
    "                        \"date\": date,\n",
    "                    }\n",
    "                )\n",
    "                speech_content_id += 1\n",
    "\n",
    "        contributions_extended = pd.concat(contributions_extended, sort=False)\n",
    "        contributions_extended.to_pickle(contributions_extended_output / f\"{session_path.stem}.pkl\")\n",
    "\n",
    "    speech_content = pd.DataFrame.from_records(speech_records)\n",
    "    speech_content.to_pickle(term_spoken_content / \"speech_content.pkl\")\n",
    "\n",
    "    contributions_simplified = pd.concat(contributions_simplified, sort=False)\n",
    "    contributions_simplified.to_pickle(CONTRIBUTIONS_SIMPLIFIED / f\"contributions_simplified_{term_number}.pkl\")\n",
    "    PATHS.FINAL_CONTRIB_SIM.mkdir(parents=True, exist_ok=True)\n",
    "    contributions_simplified.to_pickle(PATHS.FINAL_CONTRIB_SIM / f\"contributions_simplified_{term_number}.pkl\")\n",
    "\n",
    "     # Save contributions simplified to Excel\n",
    "    contributions_simplified.to_excel(PATHS.EXCEL_FINAL_STAGE / f\"contributions_simplified_{term_number}.xlsx\", index=False)\n",
    "\n",
    "\n",
    "# Dictionary to collect contribution simplified periods\n",
    "simplified_contribs_by_term = {}\n",
    "\n",
    "for term_number in [19, 20]:\n",
    "    simplified_path = CONTRIBUTIONS_SIMPLIFIED / f\"contributions_simplified_{term_number}.pkl\"\n",
    "    df = pd.read_pickle(simplified_path)\n",
    "    simplified_contribs_by_term[term_number] = df\n",
    "\n",
    "# make combinedcontributions simplified file\n",
    "if simplified_contribs_by_term:\n",
    "    combined_df = pd.concat(simplified_contribs_by_term.values(), ignore_index=True)\n",
    "    combined_df.to_pickle(CONTRIBUTIONS_SIMPLIFIED / \"contributions_simplified_19_20.pkl\")\n",
    "    combined_df.to_pickle(PATHS.FINAL_CONTRIB_SIM / f\"contributions_simplified_19_20.pkl\")\n",
    "    combined_df.to_excel(PATHS.EXCEL_FINAL_STAGE  / f\"contributions_simplified_19_20.xlsx\", index=False)\n",
    "\n",
    "\n",
    "# Save speech content to Excel\n",
    "df = pd.read_pickle(PATHS.SPEECH_CONTENT_04_19 / \"speech_content.pkl\")\n",
    "df.to_excel(PATHS.EXCEL_SPEECH_STAGE04_19, index=False)\n",
    "df = pd.read_pickle(PATHS.SPEECH_CONTENT_04_20 / \"speech_content.pkl\")\n",
    "df.to_excel(PATHS.EXCEL_SPEECH_STAGE04_20, index=False)\n",
    "\n",
    "print(f\"speeches saved.\")"
   ],
   "id": "56f6d78fc0ab9514",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
